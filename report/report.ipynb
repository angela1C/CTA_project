{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Benchmarking Sorting Algorithms in Python\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [Section 1. Introduction](#1.-introduction)\n",
    "    - [2.  Five Sorting Algorithms ](#2-five-sorting-algorithms)\n",
    "    - [2.1.1 Bubble Sort: A Simple comparison-based sort](#2.1.1-bubble-sort:-a-simple-comparison-based-sort )\n",
    "    - [2.1.2 Merge Sort:  An efficient comparison based sort](#2.1.2-merge-sort:-an-efficient-comparison-based-sort)\n",
    "        - [2.1.3 Counting Sort:  A non comparison sort](#2.1.3-counting-sort:-a-non-comparison-sort)\n",
    "    - [2.1.4 Insertion Sort any other sorting algorithm of your choice](#2.1.4-insertion-sort-any-other-sorting algorithm-of-your-choice)\n",
    "    - [2.1.5 Quick Sort]\n",
    "- [Section 3 Implementation and Benchmarking](#3-implementation-and-benchmarking)\n",
    "- [References](#references)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Introduction \n",
    "\n",
    "In this section I will introduce the concept of sorting algorithms and discuss the relevance of concepts such as time and space complexity, performance, in-place sorting, stable sorting, comparator functions, comparison-based and non-comparison-based sorts.\n",
    "\n",
    "\n",
    "Much of the information here is based on Algorithms in a Nutshell by George T. Heineman, Gary Pollice and Stanley Selkow and lecture notes for the Computational Thinking with Algorithms at GMIT.\n",
    "\n",
    "[Sorting](https://www.collinsdictionary.com/dictionary/english/sorting) is the process or operation of ordering items and data according to specific criteria. Arranging items, whether manually or digitally into some order makes many common tasks easier to do. Sorted information is nearly always easier for human beings to understand and work with, whether it is looking up a number in a phone book, finding a book on a library or bookshop shelf, referring to a statistical tables book, deciding what to watch on television. It is even more applicable with technology. Social media and news feeds, emails, search items in a browser or recommendations for where to eat to what to do are all sorted according to some algorithms whether it is by date, popularity, location etc.\n",
    "\n",
    "Numerous computations and tasks can be simplified and made more efficient by having the data sorted in advance, such as searching for an item, checking for duplicate items, determining the smallest and largest values, or the most common or least common values. Sorting is a common operation in many computer applications and the search for efficient sorting algorithms dominated the early days of computing. \n",
    "\n",
    "According to [Algorithms to live by The Computer Science of Human Decisions](Brian Christian and Tom Griffiths)[2], sorting is at the very heart of what computers do and is what actually brought computers into being in the first place. The task of tabulating the US Census in the late nineteenth century became very difficult as the population grew. An inventor by the name of Herman Hollerith was inspired by the punched railway tickets of the time to devise a system of punched cards and a machine (the Hollerith Machine) to count and sort them. This system was then used for the 1890 census. Hollerith's company later merged with others in 1911 to become the Computing Tabulating Recording Company which was later renamed to International Business Machines (IBM). \n",
    "Sorting then lay behind the development of the computer in the 20th century. By the 1960's it was estimated by one study that more than a quarter of the world's computing resouces were spent on sorting.\n",
    "\n",
    "An algorithm is a set of rules to obtain the expected output from the given input. A computer programming task can be broken down into two main steps - writing the algorithm as an ordered sequence of steps that can be used to solve the problem and then implementing the sequenced of steps in a programming language such as Python so that the machine can run the algorithm. While humans can usually follow algorithms that are not very precise in order to accomplish a task, this is not the case for computers and therefore the algorithms have to be written very precisely.\n",
    "\n",
    "There are many different ways that algorithms could be designed to achieve a similar goal. Therefore there needs to be some way of deciding which algorithm is preferable for a particular use case and therefore some way of comparing the alternative algorithms is required. A well-designed algorithm should produce the correct solution for a given input using computational resources efficiently. It should have well defined inputs and outputs and the algorithm should end after a finite number of steps. Every step of the algorithm should be precisely defined so there is no ambiguity as a computer can only do what it is instructed to do.\n",
    "The algorithm should always produce a correct solution, or at least one that is within an acceptable margin of error. The algorithm should be feasible giving the computational resources such as processing power, memory, storage etc. \n",
    "\n",
    "Algorithms vary in their space and time efficiency, even those that have the same purpose such as sorting algorithms. \n",
    "While space efficiency looks at the amount of memory or storage needed to run a program/algorithm, time efficiency looks at the effect of the input data on the run time or number of operations needed to run an algorithm.\n",
    "An algorithms efficiency can be analysed in two different ways. A priori analysis (before) looks at the efficiency of an algorithm from a theoretical perspective without being concerned with the actual implementation on any particular machine.\n",
    "The relative efficiency of algorithms is analysed by comparing their *order of growth* with respect to the size of the input N and is a measure of the **complexity** of an algorithm, looking at the growth requirements as the input size increases. (The order of growth refers to how the size of the resource requirements increase as a function of the input size n.  As input size increases so too does the number of operations required and the work required).\n",
    "Complexity measures an algorithm’s efficiency with respect to internal factors, such as the time needed to run an algorithm and is a feature of the steps in the algorithms rather than the actual implementation of the algorithm. \n",
    "\n",
    "A posteriori analysis, on the other hand, is a measure of the **performance** of an algorithm and evaluates efficiency empirically, comparing algorithms implemented on the same target platform to get their relative efficiency.\n",
    "Performance depends on the actual computer resources such as time, memory, disk, speed, compiler etc required to run a specific algorithm. Performance does not affect complexity but complexity can affect performace as the algorithm's design will feed into how the code is written and implemented. (This project involves measuring the actual performance of sorting algorithms and therefore depends on the specifics of the machine used.)\n",
    "\n",
    "\n",
    "The speed of an algorithm to complete is one of the most important factors for choosing an algorithm. The speed will highly depend on the platform it is run on and therefore cannot really compare algorithms that are run on different machines with different capabilities or come to conclusions about the algorithm in general. While you could use a limited form of empirical comparison on your own machine, the results could not be applied generally. Instead the concept of complexity can be analysed mathematically. The actual time an algorithm takes to run doesn't tell the full story as it can be influenced by other factors such as the the available memory or the speed of the processor. \n",
    "\n",
    "Complexity allows for algorithms to be compared by looking at their running time as a function of the input data size and in this way see which algorithms scale well to solve problems of a nontrivial size. Algorithmic complexity typically falls into one of a number of growth families (i.e. the growth in its execution time with respect to increasing input size n is of a certain order). Complexity looks at how the resource requirements grow as the input size increases, how the time required increases as the number of inputs increase.\n",
    "Memory or storage requirements of an algorithm could also be evaluated in this manner.\n",
    "\n",
    "While there are other factors (including memory usage, storage usage, network usage, number of read-write operations) to be considered when evaluating the efficiency of an algorithm, the main focus in this project is the time efficiency - how the time taken varies with the size of the input. The algorithm should complete its task in an acceptable amount of time\n",
    "\n",
    "The runtime of sorting algorithms can be measured by measuring the actual implementation of the algorithm using a timer function like pythons `timeit` module. The theoretical runtime complexity can be measured uses Big $O$ notation which is a measure of the expected efficiency of an algorithm and measures the asymptotic behaviours of functions which means it measures how quickly a function grows or declines. The growth rate of a function is also called its *order*.  \n",
    "Big $O$ represents the relationship between the size of the input $n$ and the number of operations the algorithm takes and shows how quickly the the runtime grows as the input size increases. It is usually used to describe the complexity of an algorithm in the worst-case scenario. It could also be used to describe the execution time required or the memory space used by an algorithm. \n",
    "While for small input size n all algorithms are efficient, when the size becomes non-trivial then the order or growth of an algorithm will become more and more important.\n",
    "\n",
    "If two algorithms have the same Big $O$ notation, that does not mean they will execute in exactly the same times, but that the order of the number of operations that they will require to complete will be the same. \n",
    "\n",
    "The details of the project will look at the runtime complexity of 5 different sorting algorithms.\n",
    "\n",
    "According to [wikipedia](https://en.wikipedia.org/wiki/In-place_algorithm), *in computer science, an in-place algorithm is an algorithm which transforms input using no auxiliary data structure. However a small amount of extra storage space is allowed for auxiliary variables. The input is usually overwritten by the output as the algorithm executes. In-place algorithm updates input sequence only through replacement or swapping of elements. An algorithm which is not in-place is sometimes called not-in-place or out-of-place.*\n",
    "\n",
    "The various sorting algorithms differ from each other in their memory requirements which depends on how the actual algorithm works. When a sorting algorithm is run, it has to first read the input data from a storage location to the computers RAM. An **in-place** sorting algorithm is one that only uses a fixed additional amount of working space, no matter what the input size whereas other sorting algorithms may require additional working memory  which is often related to the input size. If there is limited memory available then in-place sorting is desirable.\n",
    "By producing the sorted output in the same memory space as the input data to be sorted avoids the need to use double the space. A sorting algorithm will still need some extra storage for working variables though.\n",
    "\n",
    "Some algorithm create empty arrays to hold sorted copies and this requires more memory as the size of the input increases. (mention which ones). In-place sorting does not require additional arrays as the relative position of the elements are swapped within the array to be sorted and therefore additional memory should not be required.\n",
    "\n",
    "A sorting algorithm is considered **comparison-based** if the only way to gain information about the total order is by comparing a pair of elements at a time using comparator operators to see which of the two elements should appear first in the sorted list. Comparison sorts do not make any assumptions about the data and compare all the elements against each other.\n",
    "Simple sorting algorithms such as Bubble Sort, Insertion Sort, and Selection Sort are comparison-based sorts.  On the other hand, there are other sorting algorithms such as Counting Sort, Bucket Sort and Radix Sort which do make some assumptions about the data. These type type of algorithms consider the distribution of the data and the range of values that the data falls into and in doing so avoiding  the need to compare all elements to each other.\n",
    "\n",
    "Numbers and single characters can be quite easily sorted. While composite elements such as strings of characters are usually sorted by sorting each individual element of the string. Two elements can be compared to each other to see if they are less than, greater than or equal to each other.  Sorting of custom objects may require a custom ordering scheme. In general a comparator function compares the elements $p$ to $q$ and returns 0 if $p$ = $q$, a negative number if $p$ < $q$, and a positive number if $p > q$. Using the example provided in the book, an airport terminal might list outbound flights in ascending order of destination city or departure time while flight numbers appear to be unordered.\n",
    "\n",
    "\n",
    "According to Algorithms in a Nutshell, if a collection of comparable elements\n",
    "$A$ is presented to be sorted in place where $A[i]$ and $ai$ refer to the ith element in the collection with $A[0]$ being the first element in the collection, then to sort the collection the elements $A$ must be reorganised so that if $A[i] < A[j]$, then $i < j$. Any duplicate elements must be contiguous in the resulting ordered collection. This means that if $A[i] = A[j]$ in a sorted collection, then there can be no $k$ such that $i < k < j$ and $A[i] ≠ A[k]$. Finally, the sorted collection A must be a permutation of the elements that originally formed $A$. \n",
    "\n",
    "The book also outlines how the elements in the collection being compared must admit a total ordering. That is, for any two elements p and q in a collection, exactly one of the following three predicates is true: `p = q`, `p < q`, or `p > q`.\n",
    "\n",
    "**Stability** means that equivalent elements will retain their relative positioning after the sorting has taken place.\n",
    "With a stable sorting algorithm the order of equal elements is the same in the input and output.\n",
    " It is an important factor to consider when sorting key value pairs where the data might contain duplicate keys. This project only looks at sorting one dimensional arrays of integers but there are many other applications of sorting where the data has more than one dimension, in which case the data is sorted based on one column of data known as the key with the rest of the data is known as satellite data and should travel with the key when it is moved to another position.\n",
    "According to [Reference: Pollice G., Selkow S. and Heineman G. (2016). Algorithms in a Nutshell, 2nd Edition. O' Reilly.], if two elements (ai and aj) in the original unsorted data are equal (as determined by the comparator function), stable sorting refers to the fact such pairs of equal elements will retain their relative ordering after the sorting has taken place. If i < j then the final location of a<sub>i</sub> must be to the left of a<sub>j</sub>. Sorting algorithms that can guarantee this property are considered stable. \n",
    "\n",
    "A sorting algorithm is considered stable if two objects with equal keys end up in the same order in the sorted output as they appear in the input. An unstable algorithm does not pay attention to the relationship between element locations in the original collection and does not guarantee the relative ordered will be kept after the sorting has taken place.\n",
    "See [geeksforgeeks](https://www.geeksforgeeks.org/stability-in-sorting-algorithms/)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2.  Sorting Algorithms \n",
    "\n",
    "Introduce each of your chosen algorithms in turn, discuss their space and time complexity, and explain how each algorithm works using your own diagrams and different example input instances.\n",
    "\n",
    "(by different example input instances, he means that each algorithm has its own average, best and worst case. The example inputs to be used in the report should highlight the behaviour of the algorithms under these different conditions.??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Bubble Sort: A Simple Comparison based sort \n",
    "\n",
    "\n",
    "The following sources are referred to in this section.\n",
    "- Computational Thinking with Algorithms lecture notes at GMIT.\n",
    "- [runestone interactive python](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheBubbleSort.html)\n",
    "- [wikipedia](https://en.wikipedia.org/wiki/Bubble_sort)\n",
    "- [programiz](https://www.programiz.com/dsa/bubble-sort), \n",
    "- [W3resources](https://www.w3resource.com/python-exercises/data-structures-and-algorithms/python-search-and-sorting-exercise-4.php), \n",
    "- [geekforgeeks](https://www.geeksforgeeks.org/bubble-sort/), [runestone interactive python](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheBubbleSort.html)\n",
    "\n",
    "Bubble Sort is a fairly simple comparison-based sorting algorithm and is so named for the way larger values in a list “bubble up” to the end as sorting takes place. The algorithm repeatedly goes through the list to be sorted, comparing and swapping adjacent elements that are out of order.  With every new pass through the data, the next largest element bubbles up towards it's correct position. Although it is quite simple to understand and to implement, it is slow and impractical for most problems apart from situations where the data is already nearly sorted.\n",
    "\n",
    "Bubble Sort works by repeatedly comparing neighbouring elements and swapping them if they are out of order. It makes multiple passes or iterations through the list and with each pass through the list, the next largest element in it's proper place.\n",
    "It starts by comparing each element in the list (except the very last one) with it's neighbour to the right, swapping the elements which are out of order. At the end of the first pass, the last and largest element is now in it's final place.\n",
    "The second pass compares each element (except the last two) with the neighbour to the right, again swapping the elements which are out of order. At the end of the second pass through the data, the largest two elements are now in their final place. \n",
    "The algorithm continues by comparing and swapping the remaining elements in the list in the same way, except those now already sorted at the end of the list. With each iteration the sorted side on the right gets bigger and the unsorted side on the left gets smaller, until there are no more unsorted elements on the left. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BubbleSort](img/Bubble_Sort.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The above diagram illustrates how the Bubble Sorting algorithm works on a small array of 5 random numbers [6, 11, 3, 9, 4].\n",
    "The example here shows how (4) $n-1$ passes are made through the array of $n$ elements. \n",
    "there are $n-1$ comparisons performed on the first pass, $n-2$ on the second pass, $n-3$ on the third pass and $n-4$ on the fourth and last pass.\n",
    "The total number of comparisons is the sum of the first n-1 integers.\n",
    "For the first pass, the algorithm iterates through the array from left to right, the first pair of elements that are out of order is `(11,3)` so the order of this pair is swapped and the array becomes `[6, 3, 11, 9, 4]`. Then the elements `11` and `9` are compared and swapped resulting in `[6, 3, 9, 11 ,4]` then `11` and `4` are swapped. At the start of the second pass, the array is now `[6,3,9,11,4]`. The first pair of elements to be swapped is `(6,3)`\n",
    "\n",
    "\n",
    "- In the first pass, swaps are made between three pairs of elements:  `(11, 3)`, `(11, 9)` then `(11, 4)`.\n",
    "- At the end of the first pass the array is now `[6, 3, 9, 4, 11]`.\n",
    "- At the end of the first pass, the largest element `11` is now in its correct position.\n",
    "- The first swap in the second pass is `(6, 3)`, then `(9, 4)` resulting in `[3, 6, 4, 9, 11]` at the end of the second pass.\n",
    "- The second largest element `9` is now in it's correct place.\n",
    "- On the third pass through the list, there is only one pair to be swapped `(6,4)`.\n",
    "- At the end of the third pass, the array is sorted `[3, 4, 6, 9, 11]` with each element in its correct sorted order.\n",
    "- Nevertheless the algorithm still does a fourth pass through the array, even though there are no more elements to be sorted.\n",
    "- The algorithm is finished.\n",
    "\n",
    "\n",
    "\n",
    "The python code to implement the Bubble Sort algorithm above is as follows. This code is widely available online and while there are some small differences, they are all largely the same. The code used in this project was adapted from code at [runestone academy](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheBubbleSort.html). There is also an optimised version of the Bubble Wort algorithm known as the `Short Bubble` which stops early if the algorithm finds that the list has become sorted already before all the loops have executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def bubbleSort(array):\n",
    "    # The outer loop goes through the elements n-1 times, if n is the number of elements in the list\n",
    "\n",
    "    for passnum in range(len(array)-1,0,-1):\n",
    "        # count down to 0 as each time another element at the end of the list is sorted.\n",
    "        # at each pass the last i elements are already in place so the inner loop is shorted by 1 each time\n",
    "        for i in range(passnum): \n",
    "            # comparing each element i with the element right beside it (i+1)  \n",
    "            if array[i] > array[i+1] : \n",
    "                # If the elements are out of order swap them so the largest element is right of the smaller one\n",
    "                array[i], array[i+1] = array[i+1], array[i]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nested loop is used to compare each element and sort them into the correct place.\n",
    "The outer loop `for passnum in range(len(alist)-1,0,-1)` starts from the second last element in the list and gets shorter each time, taking account of the fact that the elements at the end of the list are becoming sorted with each iteration of the outside loop. The inner loop goes through the elements, comparing the element on the left with the element on the right \n",
    "\n",
    "\n",
    "The `temp` variable can be replaced in the `Python` programming language by using simultaneous assignments `if array[i] > array[i+1] : array[i], array[i+1] = array[i+1], array[i]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are $n-1$ passes required where $n$ is the number of elements in the array minus 1.\n",
    "The outer loop runs $n-1$ times. At the end of each iteration, another element will be in it's final sorted position. The inner loop goes through each element in the array up to the element(s) already sorted, each time comparing each element $i$ with the element to the immediate right of it $i+1$.\n",
    "Using the `>` comparison operator, the elements are compared. If the element on the left (at index `i`) is greater in value than the element on it's right (at index `i`) then the elements are swapped.\n",
    "\n",
    "\n",
    "There are $n-1$ passes through a list of $n$ items. The total number of comparisons is the sum of the first $n-1$ integers which results in $n^2$ comparisons.\n",
    "\n",
    "\n",
    "The best case occurs where the array is already sorted, as no exchanges are actually made but the comparisons still take place.\n",
    "\n",
    "For the Bubble Sort algorithm, given an array that is almost or fully sorted it still requires $n-1$ passes through the input data. There is an optimised version of the Bubble Sort algorithm which can stop early.\n",
    "\n",
    "The average case for the Bubble Sort algorithm is that exchnages are made half the time.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Bubble Sort.\n",
    "\n",
    "The Bubble Sort algorithm here has two `for` loops where it first performs $n-1$ comparisons, then $n-2$ comparisons and so on down to the final comparison. \n",
    "\n",
    "Illustrating the worst-case scenario for the algorithm which occurs when the array to be sorted is in sorted reverse order:\n",
    "\n",
    "- given an array of ` [5, 4, 3, 2, 1]`\n",
    "- In the first pass, 4 swaps are made, `(5,4)`,`(5,3)`,`(5,2)` and `(5,1)`\n",
    "- In the second pass 3 swaps are made `(4,3)`, `(4,2)` and `(4,1)`\n",
    "- In the third pass, the 2 swaps are made, `(3,2)` and `(3,1)`\n",
    "- In the final pass, 1 swap is made, `(2,1)`.\n",
    "- In this case where all the elements were in reverse order, it tooks 10 swaps to sort the 5 element array.\n",
    " \n",
    "\n",
    "In the worst case the outer loop has to execute $n-1$ times and in the average case the inner loop executes about $\\frac{n}{2}$ times for each outer loop.\n",
    "Inside the inner loop, the comparison and swap operations take constant time $k$.\n",
    "\n",
    "So it total it performs $(n-1) + (n-2) + (n-3) ... + 2+1$ which is  $frac{n}{2}+k = \\frac{n^2}{k} \\approx O(n^2)$.\n",
    "\n",
    "(removing the constants which don't change with input size simplifies it to $n^2-n$, the $n$ is them removed as $n^2$ grows faster.\n",
    "\n",
    "The worst case scenario for Bubble sort occurs when the data to be sorted is in reverse order.\n",
    "\n",
    "The Bubble Sort algorithm here always runs in $O(n)$ times even if the array is sorted. The algorithm can be optimised to stop the algorithm if the inner loop didn't cause any swaps. \n",
    "If the optimised version of the Bubble Sort algorithm is applied on a nearly sorted array then the best case will be $O(n)$. This optimised version of the algorithm was not used here. \n",
    "\n",
    "The average case is when the elements of the array are in random order.\n",
    "\n",
    "The space complexity of Bubble Sort algorithm is $O(1)$. The only additional memory is needed for the temporary  variable used for the swapping.\n",
    "\n",
    "\n",
    "Bubble sort is an **in-place** sorting algorithm and it is **stable**. It is not a very practical algorithm to use is considered very inefficient sorting method as many exchanges are made before their final locations are known. One advantage of using the Bubble Sort over other sorting algorithms is that it is possible to determine that the list is already sorted if there are no exchanges made during the pass. The regular Bubble Sort algorithm needs to be modified to do this though.\n",
    "See [runestone](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheBubbleSort.html)\n",
    "\n",
    "## Summary of time and space complexity of Bubble Sort:\n",
    "\n",
    "- Best Case complexity: $O(n)$ \n",
    "- Average Case complexity: $O(n^2)$ \n",
    "- Worst Case complexity: $O(n^2)$\n",
    "- Space complexity:  $O(n)$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Merge Sort:  An efficient comparison based sort\n",
    "\n",
    "- See [merge sort](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheMergeSort.html), [programiz](https://www.programiz.com/dsa/merge-sort)\n",
    "\n",
    "[Merge Sort](https://en.wikipedia.org/wiki/Merge_sort) is an efficient, general-purpose, comparison-based sorting algorithm. It is a divide-and-conquer algorithm that was proposed by John von Neumann in 1945. It uses recursion to continually split the list in half. \n",
    "A sub-list of 0 or 1 items is considered sorted. Once the two halves are sorted a **merge** operation is performed which combines the two smaller sub-lists into a single sorted new sublist.\n",
    "\n",
    "A [divide-and-conquer](https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm) algorithm recursively breaks a problem down into two or more sub-problems of the same or related type until these become simple enough to be solved directly. Then the solutions to the sub-problems are combined to produce a solution to the original problem.\n",
    "\n",
    "\n",
    "The algorithm uses divide-and-conquer approach by breaking down the list into two evenly (as much as possible) sized halves, then repeatedly does this to each half until the sublist contains a single element or less. Each sub problem is then sorted recursively and the solutions to all the sub-lists are combined into a single sorted new list.\n",
    "\n",
    "A list with one or less elements is considered sorted and is the base case for the recursion to stop. If the list has more than one item then it is split in half and the algorithm is recursively called on each half. When both halves are sorted, the smaller lists are then merged or combined into a single sorted list.\n",
    "All the smaller-sublists are repeatedly merged back into a new single sorted list.\n",
    "This algorithm will need extra memory to copy the elements when sorting. The extra space is needed to store the two halves when they are extracted using the slicing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram below demostrates how the MergeSort algorithm works on a small array of random integers `[8, 6, 3, 4, 5, 2, 9]`.\n",
    "\n",
    "The array is split into a left array `[8, 6, 3]` and a right array `[4, 5, 2, 9]`.\n",
    "The left side of the array `[8, 6, 3]` is further split into `[8]` and `[6, 3]`.\n",
    "The `[8]` cannot be split any further so it is then ready to be merged. `[6, 3]` is split into `[6]` and `[3]` which are then ready to be merged.\n",
    "`[3]` and `[6]` are then  merged to become `[3,6]` and then they are merged with `[8]` resulting in a sub-array `[3,6,8]`.\n",
    "\n",
    "The right array `[4, 5, 2, 9]` is further split into `[4,5]` and `[2,9]` which are further split resulting in 4 sub-arrays `[4]`,`[5]`,`[2]` and `[9]`. The sub-arrays cannot be split any further and the merging begins. `[4]` and `[5]` are merged into `[4,5]`.\n",
    "`[2]` and `[9]` are merged into `[2,9]`. The two sorted sub-arrays `[4,5]` and `[2,9]` are then merged to become `[2, 4, 5, 9]`.\n",
    "The sorted sub-array `[3,6,8]` is then merged with the sorted right array `[2, 4, 5, 9]`.\n",
    "The result is a single sorted array of `[2, 3, 4, 5, 6, 8, 9]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MergeSort](img/MergeSort.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The python code for Merge Sort\n",
    "\n",
    "The following is the python code for the Merge Sort algorithm. This code is widely available online. \n",
    "The code used in this project is based on the code at [runestone academy](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheMergeSort.html). I have added comments to the code in the accompanying python script which is used in this benchmarking project. See `merge.py`.\n",
    "\n",
    "\n",
    "```python\n",
    "def merge_sort(array):\n",
    "    # the base case is a list with 0 or 1 elements which is is already sorted.\n",
    "\n",
    "    if len(array)>1:\n",
    "        # find the middle of the list using integer division to find the split point\n",
    "        mid = len(array)//2\n",
    "        # divide the elements into two halves using the mid point\n",
    "        # # The elements are copied into the temporary arrays left[] and right[]\n",
    "        # left contains the elements from the first half of the list (up to the mid)\n",
    "        left = array[:mid]\n",
    "        # right contains the elements from the second half of the list, (from mid to the end)\n",
    "        right = array[mid:]\n",
    "        # recursively call the function on the first (left) half\n",
    "        merge_sort(left)\n",
    "        # recursively call the function on the second (right) half\n",
    "        merge_sort(right)\n",
    "\n",
    "        # once the function has been called on the left and right half, each half should be sorted\n",
    "        # The following code does the merge part, merging the two smaller lists into a single sorted list \n",
    "        # i, j and k represents the index of the left array, right array and merged arrays respectively.\n",
    "        i ,j, k = 0,0,0\n",
    "        # The elements are placed back into the original list (array) by repeatedly taking the smallest item from the two sorted lists.\n",
    "\n",
    "        # until the left and right arrays are empty.\n",
    "        while i < len(left) and j < len(right):\n",
    "            # compare the first/next element in left and right arrays, if the left element is smaller, place this element next in the sorted array\n",
    "            if left[i] <= right[j]:\n",
    "                array[k]=left[i]\n",
    "                # increment the index of left (for the next comparison between left and right arrays)\n",
    "                i += 1\n",
    "            else:\n",
    "                # otherwise if the smallest element is in the right array, assign this element to the next position in the merged array\n",
    "                array[k]=right[j]\n",
    "                # increment the index of the right array (for the next comparison between left and right arrays)\n",
    "                j += 1\n",
    "            # after assigning another element to the merged array, increment the index by 1\n",
    "            k=k+1\n",
    "        # no elements left in right array so check if any element left in the left array, if so move to merged array\n",
    "        while i < len(left):\n",
    "            array[k]=left[i]\n",
    "            i += 1\n",
    "            k += 1\n",
    "        # no elements left in left array, so check if any elements left in the right array, if so move to merged array\n",
    "        while j < len(right):\n",
    "            array[k]=right[j]\n",
    "            j += 1\n",
    "            k += 1\n",
    "    return array\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Merge Sort algorithm uses a recursive divide-and-conquer approach which results in a worst-case running time of $O(n\\log{}n)$.\n",
    "The algorithm consists of two distinct processes, the splitting and the merging. \n",
    "- A list can be split in half $\\log n$ times where $n$ is the number of elements in the list.\n",
    "- Each item in the list will eventually be processed and placed in the sorted list. This means a list of size $n$ will require $n$ operations.\n",
    "Therefore there are $\\log  n$ splits, each of which costs $n$ for a total of $n \\log n$ operations\n",
    "- Merge Sort needs extra space to hold the left and right halves which can be a critical factor for large datasets.\n",
    "See [interactive python](https://runestone.academy/runestone/books/published/pythonds/SortSearch/TheMergeSort.html)\n",
    "\n",
    "\n",
    "Merge-Sort gives good all around performances with similar best, worst and average cases with a linearitmic $n\\log{}n)$ time complexity in each case. This makes it a good choice if predictable run-time is important.\n",
    "There are versions of Merge Sort which are particularly good for sorting data with slow access times such as data that cannot be held in RAM or are stored in linked lists. \n",
    "Merge Sort is a stable sorting algorithm.\n",
    "\n",
    "## Summary of time and space complexity of Merge Sort\n",
    "\n",
    "- Best Case complexity: $O(n\\log{}n)$\n",
    "- Average Case complexity: $O(n\\log{}n)$\n",
    "- Worst Case complexity: $O(n\\log{}n)$\n",
    "- Space complexity:  $O(n)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
